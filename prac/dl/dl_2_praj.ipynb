{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c304a174-25be-4502-bd23-855c80653d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cde1249-c360-40fb-b979-cd62d72a8d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the OCR letter recognition dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data'\n",
    "dataset = pd.read_csv(url, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b167be2-17d2-4501-a2e1-bc5d4fc70b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and labels\n",
    "X = dataset.iloc[:, 1:].values  #selecting all rows and selecting all columns from index 1\n",
    "y = dataset.iloc[:, 0].values   #selecting all rows and selecting column with index 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1bbe0af-d4c5-4019-b83b-541f08d849d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n"
     ]
    }
   ],
   "source": [
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b193a92f-4afc-4370-8f8f-b44658050bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels into numeric value\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e508bdec-ca14-489f-991a-7732013ceefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8d887a8-1f3d-4833-a8e9-31c3dc5a84cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting dataset into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f591b96f-1ac1-44de-b8bb-7da60fc168d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 15.0\n",
    "X_test = X_test / 15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "522a7944-461d-48cb-88da-7c27e3b2fa0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#we are using sequential model where layers are stacked one after another,\n",
    "#output of previous layer is given to as input to next layer\n",
    "\n",
    "model = Sequential()\n",
    "#1st layer is dense layer which consists on 128 neurons, since it is 1st layer we need to define input_shape of our training data\n",
    "model.add(Dense(128, activation='relu', input_shape=(16,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(26, activation='softmax'))  #softmax is used to predict multiclass category outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "288d0599-6c4b-4bfa-837b-d530be9ac4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we will compile the model\n",
    "\n",
    "#sparse_categorical_crossentropy (scce) produces a category index of the most likely matching category.\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3ea40a0-dfd7-4387-9620-514ccfacaeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1264 - loss: 2.9946 - val_accuracy: 0.5425 - val_loss: 1.7837\n",
      "Epoch 2/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3796 - loss: 1.9673 - val_accuracy: 0.6012 - val_loss: 1.4036\n",
      "Epoch 3/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4612 - loss: 1.6814 - val_accuracy: 0.6398 - val_loss: 1.2503\n",
      "Epoch 4/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5037 - loss: 1.5570 - val_accuracy: 0.6680 - val_loss: 1.1442\n",
      "Epoch 5/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5425 - loss: 1.4265 - val_accuracy: 0.6955 - val_loss: 1.0711\n",
      "Epoch 6/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5709 - loss: 1.3547 - val_accuracy: 0.7003 - val_loss: 1.0178\n",
      "Epoch 7/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5738 - loss: 1.3201 - val_accuracy: 0.7190 - val_loss: 0.9527\n",
      "Epoch 8/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5978 - loss: 1.2500 - val_accuracy: 0.7358 - val_loss: 0.9265\n",
      "Epoch 9/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6023 - loss: 1.2502 - val_accuracy: 0.7420 - val_loss: 0.8812\n",
      "Epoch 10/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6156 - loss: 1.2026 - val_accuracy: 0.7450 - val_loss: 0.8529\n",
      "Epoch 11/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6280 - loss: 1.1819 - val_accuracy: 0.7370 - val_loss: 0.8442\n",
      "Epoch 12/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6377 - loss: 1.1441 - val_accuracy: 0.7523 - val_loss: 0.8115\n",
      "Epoch 13/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6375 - loss: 1.1284 - val_accuracy: 0.7615 - val_loss: 0.8101\n",
      "Epoch 14/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6477 - loss: 1.1025 - val_accuracy: 0.7632 - val_loss: 0.7874\n",
      "Epoch 15/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6502 - loss: 1.1072 - val_accuracy: 0.7705 - val_loss: 0.7597\n",
      "Epoch 16/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6580 - loss: 1.0795 - val_accuracy: 0.7705 - val_loss: 0.7538\n",
      "Epoch 17/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6548 - loss: 1.0631 - val_accuracy: 0.7828 - val_loss: 0.7319\n",
      "Epoch 18/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6560 - loss: 1.0765 - val_accuracy: 0.7782 - val_loss: 0.7175\n",
      "Epoch 19/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6646 - loss: 1.0497 - val_accuracy: 0.7853 - val_loss: 0.7329\n",
      "Epoch 20/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6730 - loss: 1.0389 - val_accuracy: 0.7890 - val_loss: 0.7102\n",
      "Epoch 21/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6706 - loss: 1.0436 - val_accuracy: 0.7910 - val_loss: 0.6914\n",
      "Epoch 22/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6697 - loss: 1.0174 - val_accuracy: 0.7995 - val_loss: 0.6694\n",
      "Epoch 23/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6757 - loss: 1.0075 - val_accuracy: 0.8027 - val_loss: 0.6730\n",
      "Epoch 24/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6809 - loss: 1.0087 - val_accuracy: 0.8015 - val_loss: 0.6809\n",
      "Epoch 25/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6789 - loss: 1.0099 - val_accuracy: 0.7995 - val_loss: 0.6686\n",
      "Epoch 26/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6798 - loss: 0.9877 - val_accuracy: 0.8027 - val_loss: 0.6599\n",
      "Epoch 27/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6935 - loss: 0.9789 - val_accuracy: 0.8037 - val_loss: 0.6533\n",
      "Epoch 28/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6898 - loss: 0.9702 - val_accuracy: 0.8025 - val_loss: 0.6505\n",
      "Epoch 29/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6864 - loss: 0.9759 - val_accuracy: 0.8112 - val_loss: 0.6310\n",
      "Epoch 30/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6966 - loss: 0.9556 - val_accuracy: 0.8065 - val_loss: 0.6409\n",
      "Epoch 31/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7017 - loss: 0.9260 - val_accuracy: 0.8048 - val_loss: 0.6395\n",
      "Epoch 32/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6901 - loss: 0.9641 - val_accuracy: 0.8133 - val_loss: 0.6175\n",
      "Epoch 33/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6947 - loss: 0.9622 - val_accuracy: 0.8127 - val_loss: 0.6147\n",
      "Epoch 34/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6955 - loss: 0.9824 - val_accuracy: 0.8100 - val_loss: 0.6331\n",
      "Epoch 35/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6931 - loss: 0.9667 - val_accuracy: 0.8120 - val_loss: 0.6177\n",
      "Epoch 36/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7041 - loss: 0.9410 - val_accuracy: 0.8140 - val_loss: 0.6163\n",
      "Epoch 37/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6990 - loss: 0.9498 - val_accuracy: 0.8155 - val_loss: 0.6040\n",
      "Epoch 38/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7007 - loss: 0.9258 - val_accuracy: 0.8200 - val_loss: 0.5990\n",
      "Epoch 39/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6950 - loss: 0.9494 - val_accuracy: 0.8210 - val_loss: 0.6070\n",
      "Epoch 40/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7082 - loss: 0.9217 - val_accuracy: 0.8220 - val_loss: 0.6005\n",
      "Epoch 41/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7017 - loss: 0.9556 - val_accuracy: 0.8183 - val_loss: 0.5958\n",
      "Epoch 42/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7028 - loss: 0.9327 - val_accuracy: 0.8232 - val_loss: 0.5772\n",
      "Epoch 43/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7060 - loss: 0.9142 - val_accuracy: 0.8278 - val_loss: 0.5749\n",
      "Epoch 44/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7028 - loss: 0.9213 - val_accuracy: 0.8190 - val_loss: 0.5929\n",
      "Epoch 45/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7073 - loss: 0.9297 - val_accuracy: 0.8250 - val_loss: 0.5845\n",
      "Epoch 46/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7016 - loss: 0.9516 - val_accuracy: 0.8255 - val_loss: 0.5940\n",
      "Epoch 47/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7094 - loss: 0.9009 - val_accuracy: 0.8257 - val_loss: 0.5873\n",
      "Epoch 48/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7024 - loss: 0.9178 - val_accuracy: 0.8298 - val_loss: 0.5679\n",
      "Epoch 49/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7148 - loss: 0.9034 - val_accuracy: 0.8260 - val_loss: 0.5637\n",
      "Epoch 50/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7069 - loss: 0.9175 - val_accuracy: 0.8280 - val_loss: 0.5667\n"
     ]
    }
   ],
   "source": [
    "#The batch size is a number of samples processed before the model is updated.\n",
    "#verbose is the choice that how you want to see the output of your Nural Network while it's training.\n",
    "#If you set verbose = 0, It will show nothing\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=12, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3b7570b-98cd-4b93-a75e-b0a6be5c10ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8257 - loss: 0.5744\n",
      "Test accuracy: 0.828000009059906\n",
      "Test loss: 0.5666822195053101\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", accuracy)\n",
    "print(\"Test loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d934d1b-1f02-43fb-a4fd-26aa27483669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('ocr_model.h5')\n",
    "# Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "deeec41b-54b6-4579-b431-5e6530bb90aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('ocr_model.h5')\n",
    "# Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "207ff5b6-bccb-4729-af6b-109668d26b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_records = X_test[:1000]\n",
    "# Select a few records for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e27e5ed-69a9-46bd-b7e5-d4abe863a140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Perform classification\n",
    "predictions = model.predict(sample_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf82c83f-28c4-44ff-bae2-8ae71a1a9539",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "predicted_letters = label_encoder.inverse_transform(predicted_labels)\n",
    "actual_letters = label_encoder.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffe321c2-7e4f-427b-b173-3a7ded0b4407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = np.sum(predicted_labels == y[:1000]) / len(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "538a53f1-020a-4439-97b0-f6bd16812fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels\tActual Labels\n",
      "D\t\t\tD\n",
      "D\t\t\tD\n",
      "V\t\t\tV\n",
      "B\t\t\tB\n",
      "H\t\t\tH\n",
      "N\t\t\tN\n",
      "R\t\t\tE\n",
      "Q\t\t\tQ\n",
      "E\t\t\tR\n",
      "N\t\t\tN\n",
      "Q\t\t\tQ\n",
      "G\t\t\tO\n",
      "N\t\t\tN\n",
      "B\t\t\tD\n",
      "I\t\t\tI\n",
      "M\t\t\tM\n",
      "U\t\t\tU\n",
      "S\t\t\tS\n",
      "O\t\t\tO\n",
      "A\t\t\tA\n",
      "X\t\t\tX\n",
      "A\t\t\tA\n",
      "K\t\t\tK\n",
      "S\t\t\tS\n",
      "O\t\t\tO\n",
      "V\t\t\tV\n",
      "Y\t\t\tY\n",
      "J\t\t\tJ\n",
      "D\t\t\tD\n",
      "V\t\t\tV\n",
      "N\t\t\tD\n",
      "V\t\t\tV\n",
      "K\t\t\tK\n",
      "F\t\t\tF\n",
      "N\t\t\tN\n",
      "I\t\t\tI\n",
      "G\t\t\tG\n",
      "T\t\t\tT\n",
      "H\t\t\tH\n",
      "K\t\t\tK\n",
      "J\t\t\tJ\n",
      "O\t\t\tO\n",
      "M\t\t\tM\n",
      "T\t\t\tT\n",
      "B\t\t\tB\n",
      "Q\t\t\tQ\n",
      "Z\t\t\tZ\n",
      "C\t\t\tC\n",
      "D\t\t\tD\n",
      "X\t\t\tX\n",
      "K\t\t\tC\n",
      "G\t\t\tG\n",
      "Q\t\t\tQ\n",
      "F\t\t\tF\n",
      "N\t\t\tN\n",
      "Y\t\t\tY\n",
      "Z\t\t\tZ\n",
      "K\t\t\tK\n",
      "S\t\t\tC\n",
      "K\t\t\tT\n",
      "M\t\t\tM\n",
      "W\t\t\tV\n",
      "Q\t\t\tG\n",
      "O\t\t\tM\n",
      "F\t\t\tD\n",
      "T\t\t\tT\n",
      "H\t\t\tH\n",
      "P\t\t\tP\n",
      "N\t\t\tN\n",
      "C\t\t\tC\n",
      "O\t\t\tO\n",
      "X\t\t\tX\n",
      "X\t\t\tX\n",
      "Q\t\t\tQ\n",
      "V\t\t\tV\n",
      "F\t\t\tP\n",
      "V\t\t\tV\n",
      "G\t\t\tG\n",
      "W\t\t\tW\n",
      "H\t\t\tH\n",
      "P\t\t\tP\n",
      "O\t\t\tO\n",
      "I\t\t\tI\n",
      "G\t\t\tG\n",
      "X\t\t\tX\n",
      "Y\t\t\tX\n",
      "Y\t\t\tP\n",
      "W\t\t\tW\n",
      "O\t\t\tQ\n",
      "D\t\t\tD\n",
      "B\t\t\tN\n",
      "Q\t\t\tQ\n",
      "T\t\t\tT\n",
      "T\t\t\tT\n",
      "V\t\t\tV\n",
      "Y\t\t\tY\n",
      "I\t\t\tT\n",
      "V\t\t\tV\n",
      "J\t\t\tJ\n",
      "U\t\t\tU\n",
      "D\t\t\tD\n",
      "L\t\t\tL\n",
      "M\t\t\tM\n",
      "Y\t\t\tY\n",
      "E\t\t\tE\n",
      "M\t\t\tM\n",
      "A\t\t\tA\n",
      "Y\t\t\tY\n",
      "K\t\t\tK\n",
      "Y\t\t\tY\n",
      "U\t\t\tU\n",
      "U\t\t\tU\n",
      "U\t\t\tU\n",
      "E\t\t\tC\n",
      "Q\t\t\tQ\n",
      "I\t\t\tI\n",
      "A\t\t\tA\n",
      "E\t\t\tE\n",
      "B\t\t\tD\n",
      "T\t\t\tT\n",
      "B\t\t\tP\n",
      "Q\t\t\tQ\n",
      "Z\t\t\tZ\n",
      "G\t\t\tG\n",
      "X\t\t\tX\n",
      "G\t\t\tG\n",
      "F\t\t\tF\n",
      "M\t\t\tM\n",
      "Z\t\t\tS\n",
      "E\t\t\tE\n",
      "E\t\t\tE\n",
      "K\t\t\tK\n",
      "Z\t\t\tZ\n",
      "K\t\t\tX\n",
      "O\t\t\tO\n",
      "E\t\t\tE\n",
      "U\t\t\tU\n",
      "I\t\t\tI\n",
      "R\t\t\tR\n",
      "O\t\t\tO\n",
      "M\t\t\tM\n",
      "J\t\t\tJ\n",
      "F\t\t\tF\n",
      "K\t\t\tK\n",
      "M\t\t\tM\n",
      "N\t\t\tN\n",
      "G\t\t\tT\n",
      "D\t\t\tD\n",
      "H\t\t\tH\n",
      "R\t\t\tR\n",
      "L\t\t\tL\n",
      "Z\t\t\tZ\n",
      "F\t\t\tF\n",
      "V\t\t\tV\n",
      "W\t\t\tW\n",
      "E\t\t\tE\n",
      "T\t\t\tT\n",
      "W\t\t\tW\n",
      "Y\t\t\tY\n",
      "Q\t\t\tQ\n",
      "L\t\t\tL\n",
      "F\t\t\tF\n",
      "O\t\t\tO\n",
      "D\t\t\tD\n",
      "K\t\t\tK\n",
      "S\t\t\tI\n",
      "T\t\t\tX\n",
      "P\t\t\tP\n",
      "H\t\t\tH\n",
      "Q\t\t\tZ\n",
      "D\t\t\tH\n",
      "W\t\t\tW\n",
      "T\t\t\tF\n",
      "B\t\t\tB\n",
      "R\t\t\tR\n",
      "O\t\t\tO\n",
      "B\t\t\tB\n",
      "Z\t\t\tZ\n",
      "N\t\t\tN\n",
      "W\t\t\tW\n",
      "Z\t\t\tZ\n",
      "W\t\t\tW\n",
      "V\t\t\tV\n",
      "B\t\t\tS\n",
      "V\t\t\tY\n",
      "H\t\t\tH\n",
      "Q\t\t\tO\n",
      "T\t\t\tY\n",
      "V\t\t\tV\n",
      "S\t\t\tS\n",
      "W\t\t\tW\n",
      "B\t\t\tB\n",
      "P\t\t\tP\n",
      "D\t\t\tD\n",
      "Z\t\t\tZ\n",
      "O\t\t\tO\n",
      "X\t\t\tX\n",
      "F\t\t\tP\n",
      "B\t\t\tB\n",
      "S\t\t\tS\n",
      "T\t\t\tT\n",
      "X\t\t\tX\n",
      "J\t\t\tJ\n",
      "B\t\t\tB\n",
      "Y\t\t\tY\n",
      "S\t\t\tI\n",
      "Z\t\t\tZ\n",
      "Z\t\t\tZ\n",
      "P\t\t\tP\n",
      "E\t\t\tE\n",
      "H\t\t\tH\n",
      "Q\t\t\tQ\n",
      "P\t\t\tI\n",
      "A\t\t\tA\n",
      "H\t\t\tH\n",
      "F\t\t\tP\n",
      "E\t\t\tE\n",
      "U\t\t\tU\n",
      "K\t\t\tK\n",
      "P\t\t\tP\n",
      "M\t\t\tM\n",
      "C\t\t\tC\n",
      "X\t\t\tY\n",
      "J\t\t\tJ\n",
      "W\t\t\tW\n",
      "M\t\t\tM\n",
      "G\t\t\tG\n",
      "J\t\t\tJ\n",
      "O\t\t\tO\n",
      "X\t\t\tH\n",
      "P\t\t\tP\n",
      "L\t\t\tL\n",
      "W\t\t\tW\n",
      "A\t\t\tA\n",
      "C\t\t\tC\n",
      "C\t\t\tC\n",
      "C\t\t\tC\n",
      "O\t\t\tO\n",
      "J\t\t\tJ\n",
      "Y\t\t\tY\n",
      "P\t\t\tP\n",
      "Y\t\t\tY\n",
      "A\t\t\tA\n",
      "R\t\t\tR\n",
      "Z\t\t\tZ\n",
      "J\t\t\tJ\n",
      "I\t\t\tI\n",
      "G\t\t\tG\n",
      "G\t\t\tG\n",
      "I\t\t\tI\n",
      "N\t\t\tK\n",
      "G\t\t\tM\n",
      "R\t\t\tR\n",
      "T\t\t\tT\n",
      "B\t\t\tD\n",
      "E\t\t\tE\n",
      "D\t\t\tD\n",
      "L\t\t\tL\n",
      "W\t\t\tW\n",
      "G\t\t\tP\n",
      "L\t\t\tL\n",
      "U\t\t\tU\n",
      "O\t\t\tO\n",
      "T\t\t\tT\n",
      "A\t\t\tA\n",
      "V\t\t\tV\n",
      "D\t\t\tD\n",
      "U\t\t\tU\n",
      "X\t\t\tX\n",
      "X\t\t\tX\n",
      "G\t\t\tG\n",
      "C\t\t\tC\n",
      "D\t\t\tF\n",
      "Z\t\t\tZ\n",
      "W\t\t\tW\n",
      "T\t\t\tT\n",
      "V\t\t\tV\n",
      "T\t\t\tT\n",
      "P\t\t\tP\n",
      "M\t\t\tM\n",
      "S\t\t\tS\n",
      "U\t\t\tU\n",
      "X\t\t\tF\n",
      "Q\t\t\tQ\n",
      "G\t\t\tB\n",
      "G\t\t\tG\n",
      "K\t\t\tK\n",
      "L\t\t\tL\n",
      "F\t\t\tF\n",
      "E\t\t\tE\n",
      "R\t\t\tR\n",
      "P\t\t\tP\n",
      "R\t\t\tR\n",
      "W\t\t\tW\n",
      "I\t\t\tI\n",
      "Q\t\t\tY\n",
      "Y\t\t\tY\n",
      "B\t\t\tB\n",
      "C\t\t\tC\n",
      "T\t\t\tT\n",
      "M\t\t\tM\n",
      "M\t\t\tM\n",
      "D\t\t\tN\n",
      "B\t\t\tB\n",
      "R\t\t\tR\n",
      "Z\t\t\tZ\n",
      "G\t\t\tG\n",
      "D\t\t\tD\n",
      "R\t\t\tR\n",
      "I\t\t\tI\n",
      "Y\t\t\tY\n",
      "F\t\t\tP\n",
      "M\t\t\tM\n",
      "A\t\t\tA\n",
      "B\t\t\tB\n",
      "M\t\t\tM\n",
      "R\t\t\tF\n",
      "G\t\t\tG\n",
      "Q\t\t\tQ\n",
      "Z\t\t\tZ\n",
      "P\t\t\tP\n",
      "O\t\t\tO\n",
      "Q\t\t\tQ\n",
      "P\t\t\tP\n",
      "G\t\t\tG\n",
      "N\t\t\tN\n",
      "O\t\t\tO\n",
      "T\t\t\tT\n",
      "G\t\t\tG\n",
      "S\t\t\tS\n",
      "V\t\t\tV\n",
      "A\t\t\tZ\n",
      "A\t\t\tA\n",
      "P\t\t\tP\n",
      "J\t\t\tJ\n",
      "O\t\t\tO\n",
      "N\t\t\tN\n",
      "Q\t\t\tQ\n",
      "K\t\t\tK\n",
      "X\t\t\tX\n",
      "S\t\t\tE\n",
      "F\t\t\tP\n",
      "J\t\t\tJ\n",
      "N\t\t\tN\n",
      "X\t\t\tX\n",
      "X\t\t\tX\n",
      "V\t\t\tV\n",
      "Q\t\t\tQ\n",
      "Y\t\t\tH\n",
      "A\t\t\tA\n",
      "T\t\t\tT\n",
      "S\t\t\tS\n",
      "W\t\t\tW\n",
      "M\t\t\tM\n",
      "P\t\t\tP\n",
      "Y\t\t\tY\n",
      "M\t\t\tU\n",
      "S\t\t\tZ\n",
      "R\t\t\tR\n",
      "B\t\t\tB\n",
      "A\t\t\tA\n",
      "Y\t\t\tY\n",
      "F\t\t\tF\n",
      "F\t\t\tF\n",
      "B\t\t\tD\n",
      "A\t\t\tA\n",
      "N\t\t\tN\n",
      "A\t\t\tA\n",
      "K\t\t\tH\n",
      "Q\t\t\tQ\n",
      "P\t\t\tP\n",
      "Z\t\t\tZ\n",
      "R\t\t\tR\n",
      "B\t\t\tD\n",
      "W\t\t\tW\n",
      "R\t\t\tO\n",
      "Q\t\t\tQ\n",
      "K\t\t\tK\n",
      "N\t\t\tN\n",
      "W\t\t\tW\n",
      "P\t\t\tP\n",
      "W\t\t\tW\n",
      "S\t\t\tS\n",
      "K\t\t\tK\n",
      "S\t\t\tS\n",
      "I\t\t\tJ\n",
      "E\t\t\tE\n",
      "S\t\t\tS\n",
      "V\t\t\tV\n",
      "S\t\t\tS\n",
      "O\t\t\tO\n",
      "V\t\t\tV\n",
      "G\t\t\tT\n",
      "X\t\t\tX\n",
      "Q\t\t\tQ\n",
      "W\t\t\tW\n",
      "I\t\t\tI\n",
      "Z\t\t\tZ\n",
      "B\t\t\tD\n",
      "F\t\t\tF\n",
      "P\t\t\tP\n",
      "O\t\t\tR\n",
      "P\t\t\tP\n",
      "C\t\t\tC\n",
      "D\t\t\tD\n",
      "J\t\t\tJ\n",
      "R\t\t\tL\n",
      "I\t\t\tI\n",
      "D\t\t\tH\n",
      "X\t\t\tX\n",
      "B\t\t\tD\n",
      "U\t\t\tU\n",
      "G\t\t\tG\n",
      "O\t\t\tO\n",
      "K\t\t\tK\n",
      "K\t\t\tK\n",
      "K\t\t\tK\n",
      "P\t\t\tP\n",
      "P\t\t\tP\n",
      "G\t\t\tG\n",
      "T\t\t\tT\n",
      "F\t\t\tF\n",
      "B\t\t\tB\n",
      "Y\t\t\tY\n",
      "V\t\t\tY\n",
      "I\t\t\tI\n",
      "H\t\t\tH\n",
      "E\t\t\tE\n",
      "S\t\t\tS\n",
      "Y\t\t\tY\n",
      "S\t\t\tS\n",
      "T\t\t\tT\n",
      "Q\t\t\tQ\n",
      "L\t\t\tL\n",
      "R\t\t\tM\n",
      "I\t\t\tI\n",
      "Z\t\t\tZ\n",
      "F\t\t\tF\n",
      "A\t\t\tA\n",
      "J\t\t\tJ\n",
      "B\t\t\tV\n",
      "Q\t\t\tG\n",
      "U\t\t\tU\n",
      "S\t\t\tZ\n",
      "H\t\t\tH\n",
      "O\t\t\tO\n",
      "H\t\t\tN\n",
      "A\t\t\tJ\n",
      "G\t\t\tT\n",
      "O\t\t\tO\n",
      "H\t\t\tH\n",
      "Q\t\t\tV\n",
      "F\t\t\tF\n",
      "L\t\t\tL\n",
      "W\t\t\tW\n",
      "M\t\t\tM\n",
      "T\t\t\tY\n",
      "J\t\t\tJ\n",
      "P\t\t\tP\n",
      "W\t\t\tW\n",
      "E\t\t\tE\n",
      "A\t\t\tA\n",
      "B\t\t\tB\n",
      "W\t\t\tN\n",
      "R\t\t\tO\n",
      "Q\t\t\tQ\n",
      "Y\t\t\tY\n",
      "Q\t\t\tQ\n",
      "F\t\t\tF\n",
      "A\t\t\tA\n",
      "A\t\t\tA\n",
      "Q\t\t\tQ\n",
      "Z\t\t\tZ\n",
      "E\t\t\tE\n",
      "K\t\t\tH\n",
      "N\t\t\tN\n",
      "E\t\t\tE\n",
      "A\t\t\tA\n",
      "R\t\t\tR\n",
      "G\t\t\tC\n",
      "Z\t\t\tZ\n",
      "Q\t\t\tQ\n",
      "V\t\t\tV\n",
      "O\t\t\tO\n",
      "F\t\t\tT\n",
      "K\t\t\tK\n",
      "M\t\t\tM\n",
      "R\t\t\tR\n",
      "Y\t\t\tY\n",
      "X\t\t\tX\n",
      "X\t\t\tX\n",
      "J\t\t\tJ\n",
      "X\t\t\tX\n",
      "Q\t\t\tQ\n",
      "T\t\t\tT\n",
      "S\t\t\tS\n",
      "A\t\t\tA\n",
      "X\t\t\tX\n",
      "G\t\t\tG\n",
      "T\t\t\tT\n",
      "N\t\t\tN\n",
      "B\t\t\tS\n",
      "Y\t\t\tY\n",
      "P\t\t\tP\n",
      "A\t\t\tA\n",
      "S\t\t\tI\n",
      "T\t\t\tT\n",
      "Q\t\t\tX\n",
      "X\t\t\tX\n",
      "C\t\t\tC\n",
      "O\t\t\tO\n",
      "B\t\t\tB\n",
      "G\t\t\tG\n",
      "R\t\t\tW\n",
      "D\t\t\tD\n",
      "K\t\t\tK\n",
      "U\t\t\tU\n",
      "S\t\t\tS\n",
      "W\t\t\tO\n",
      "Z\t\t\tZ\n",
      "S\t\t\tL\n",
      "D\t\t\tN\n",
      "R\t\t\tR\n",
      "V\t\t\tV\n",
      "A\t\t\tA\n",
      "K\t\t\tL\n",
      "B\t\t\tD\n",
      "W\t\t\tW\n",
      "I\t\t\tI\n",
      "R\t\t\tO\n",
      "C\t\t\tC\n",
      "W\t\t\tW\n",
      "A\t\t\tA\n",
      "Y\t\t\tY\n",
      "Q\t\t\tQ\n",
      "L\t\t\tL\n",
      "G\t\t\tQ\n",
      "K\t\t\tK\n",
      "J\t\t\tJ\n",
      "E\t\t\tE\n",
      "B\t\t\tB\n",
      "P\t\t\tP\n",
      "J\t\t\tJ\n",
      "R\t\t\tR\n",
      "X\t\t\tX\n",
      "N\t\t\tN\n",
      "A\t\t\tA\n",
      "G\t\t\tG\n",
      "C\t\t\tC\n",
      "D\t\t\tT\n",
      "L\t\t\tL\n",
      "S\t\t\tS\n",
      "A\t\t\tA\n",
      "N\t\t\tN\n",
      "G\t\t\tK\n",
      "V\t\t\tV\n",
      "S\t\t\tG\n",
      "A\t\t\tA\n",
      "D\t\t\tD\n",
      "H\t\t\tH\n",
      "W\t\t\tY\n",
      "Z\t\t\tZ\n",
      "Q\t\t\tQ\n",
      "C\t\t\tC\n",
      "U\t\t\tU\n",
      "Q\t\t\tQ\n",
      "Z\t\t\tZ\n",
      "M\t\t\tM\n",
      "D\t\t\tD\n",
      "B\t\t\tB\n",
      "L\t\t\tL\n",
      "R\t\t\tR\n",
      "Q\t\t\tQ\n",
      "D\t\t\tD\n",
      "F\t\t\tF\n",
      "W\t\t\tW\n",
      "Q\t\t\tQ\n",
      "M\t\t\tM\n",
      "G\t\t\tG\n",
      "Z\t\t\tZ\n",
      "B\t\t\tB\n",
      "U\t\t\tU\n",
      "N\t\t\tN\n",
      "E\t\t\tK\n",
      "Q\t\t\tP\n",
      "A\t\t\tA\n",
      "W\t\t\tU\n",
      "F\t\t\tF\n",
      "F\t\t\tT\n",
      "X\t\t\tX\n",
      "L\t\t\tL\n",
      "U\t\t\tU\n",
      "Y\t\t\tY\n",
      "P\t\t\tP\n",
      "Y\t\t\tY\n",
      "R\t\t\tR\n",
      "S\t\t\tS\n",
      "K\t\t\tK\n",
      "G\t\t\tE\n",
      "Q\t\t\tQ\n",
      "F\t\t\tF\n",
      "W\t\t\tW\n",
      "Q\t\t\tP\n",
      "P\t\t\tP\n",
      "M\t\t\tM\n",
      "N\t\t\tN\n",
      "Z\t\t\tZ\n",
      "G\t\t\tG\n",
      "R\t\t\tK\n",
      "O\t\t\tO\n",
      "W\t\t\tW\n",
      "I\t\t\tI\n",
      "F\t\t\tC\n",
      "E\t\t\tE\n",
      "U\t\t\tU\n",
      "R\t\t\tR\n",
      "F\t\t\tI\n",
      "Y\t\t\tY\n",
      "J\t\t\tS\n",
      "V\t\t\tV\n",
      "R\t\t\tR\n",
      "C\t\t\tC\n",
      "Q\t\t\tQ\n",
      "C\t\t\tC\n",
      "Z\t\t\tJ\n",
      "Y\t\t\tY\n",
      "S\t\t\tS\n",
      "K\t\t\tK\n",
      "G\t\t\tL\n",
      "X\t\t\tX\n",
      "T\t\t\tT\n",
      "I\t\t\tI\n",
      "F\t\t\tF\n",
      "W\t\t\tW\n",
      "A\t\t\tA\n",
      "O\t\t\tD\n",
      "K\t\t\tK\n",
      "A\t\t\tA\n",
      "Z\t\t\tZ\n",
      "M\t\t\tM\n",
      "G\t\t\tG\n",
      "G\t\t\tG\n",
      "W\t\t\tW\n",
      "W\t\t\tW\n",
      "Z\t\t\tZ\n",
      "W\t\t\tW\n",
      "T\t\t\tT\n",
      "O\t\t\tO\n",
      "R\t\t\tR\n",
      "T\t\t\tT\n",
      "N\t\t\tN\n",
      "S\t\t\tS\n",
      "Q\t\t\tQ\n",
      "J\t\t\tJ\n",
      "Q\t\t\tQ\n",
      "M\t\t\tM\n",
      "O\t\t\tO\n",
      "A\t\t\tA\n",
      "N\t\t\tN\n",
      "Z\t\t\tZ\n",
      "B\t\t\tD\n",
      "T\t\t\tT\n",
      "J\t\t\tI\n",
      "U\t\t\tU\n",
      "A\t\t\tA\n",
      "O\t\t\tN\n",
      "U\t\t\tG\n",
      "G\t\t\tP\n",
      "L\t\t\tL\n",
      "S\t\t\tF\n",
      "R\t\t\tR\n",
      "C\t\t\tC\n",
      "P\t\t\tP\n",
      "Y\t\t\tY\n",
      "Y\t\t\tY\n",
      "T\t\t\tT\n",
      "A\t\t\tA\n",
      "S\t\t\tY\n",
      "T\t\t\tT\n",
      "Q\t\t\tE\n",
      "T\t\t\tT\n",
      "O\t\t\tO\n",
      "S\t\t\tS\n",
      "N\t\t\tN\n",
      "O\t\t\tO\n",
      "I\t\t\tI\n",
      "O\t\t\tO\n",
      "U\t\t\tU\n",
      "N\t\t\tN\n",
      "Z\t\t\tZ\n",
      "J\t\t\tJ\n",
      "C\t\t\tC\n",
      "N\t\t\tH\n",
      "S\t\t\tS\n",
      "G\t\t\tL\n",
      "H\t\t\tH\n",
      "E\t\t\tC\n",
      "Q\t\t\tQ\n",
      "F\t\t\tF\n",
      "B\t\t\tB\n",
      "W\t\t\tO\n",
      "I\t\t\tI\n",
      "K\t\t\tK\n",
      "O\t\t\tO\n",
      "B\t\t\tR\n",
      "G\t\t\tE\n",
      "L\t\t\tL\n",
      "M\t\t\tM\n",
      "L\t\t\tL\n",
      "X\t\t\tT\n",
      "E\t\t\tE\n",
      "U\t\t\tU\n",
      "W\t\t\tW\n",
      "E\t\t\tF\n",
      "D\t\t\tD\n",
      "N\t\t\tN\n",
      "V\t\t\tV\n",
      "M\t\t\tM\n",
      "I\t\t\tI\n",
      "K\t\t\tK\n",
      "L\t\t\tL\n",
      "Y\t\t\tY\n",
      "Q\t\t\tQ\n",
      "F\t\t\tF\n",
      "U\t\t\tU\n",
      "J\t\t\tJ\n",
      "V\t\t\tV\n",
      "M\t\t\tM\n",
      "P\t\t\tP\n",
      "W\t\t\tW\n",
      "L\t\t\tL\n",
      "A\t\t\tA\n",
      "L\t\t\tL\n",
      "B\t\t\tB\n",
      "Y\t\t\tY\n",
      "I\t\t\tI\n",
      "D\t\t\tD\n",
      "R\t\t\tR\n",
      "T\t\t\tT\n",
      "Q\t\t\tQ\n",
      "B\t\t\tB\n",
      "O\t\t\tU\n",
      "M\t\t\tM\n",
      "O\t\t\tO\n",
      "I\t\t\tI\n",
      "U\t\t\tU\n",
      "U\t\t\tU\n",
      "K\t\t\tK\n",
      "X\t\t\tJ\n",
      "I\t\t\tI\n",
      "W\t\t\tW\n",
      "Z\t\t\tZ\n",
      "Z\t\t\tZ\n",
      "P\t\t\tP\n",
      "A\t\t\tA\n",
      "Z\t\t\tZ\n",
      "P\t\t\tP\n",
      "V\t\t\tV\n",
      "O\t\t\tG\n",
      "B\t\t\tB\n",
      "G\t\t\tG\n",
      "O\t\t\tO\n",
      "V\t\t\tV\n",
      "D\t\t\tD\n",
      "Z\t\t\tZ\n",
      "Y\t\t\tY\n",
      "P\t\t\tP\n",
      "Q\t\t\tQ\n",
      "A\t\t\tA\n",
      "E\t\t\tE\n",
      "W\t\t\tW\n",
      "D\t\t\tD\n",
      "J\t\t\tJ\n",
      "I\t\t\tI\n",
      "J\t\t\tJ\n",
      "X\t\t\tX\n",
      "E\t\t\tS\n",
      "Z\t\t\tZ\n",
      "G\t\t\tG\n",
      "X\t\t\tT\n",
      "U\t\t\tU\n",
      "K\t\t\tK\n",
      "G\t\t\tG\n",
      "I\t\t\tI\n",
      "N\t\t\tN\n",
      "Z\t\t\tI\n",
      "W\t\t\tW\n",
      "I\t\t\tI\n",
      "I\t\t\tI\n",
      "P\t\t\tP\n",
      "B\t\t\tB\n",
      "O\t\t\tO\n",
      "H\t\t\tH\n",
      "F\t\t\tD\n",
      "O\t\t\tO\n",
      "N\t\t\tN\n",
      "Z\t\t\tS\n",
      "D\t\t\tD\n",
      "S\t\t\tS\n",
      "M\t\t\tM\n",
      "O\t\t\tO\n",
      "W\t\t\tN\n",
      "Y\t\t\tY\n",
      "X\t\t\tX\n",
      "Q\t\t\tQ\n",
      "W\t\t\tM\n",
      "R\t\t\tR\n",
      "G\t\t\tG\n",
      "Q\t\t\tG\n",
      "A\t\t\tA\n",
      "R\t\t\tK\n",
      "U\t\t\tU\n",
      "O\t\t\tO\n",
      "B\t\t\tP\n",
      "C\t\t\tC\n",
      "V\t\t\tV\n",
      "B\t\t\tD\n",
      "B\t\t\tB\n",
      "A\t\t\tA\n",
      "K\t\t\tE\n",
      "B\t\t\tR\n",
      "T\t\t\tT\n",
      "I\t\t\tI\n",
      "J\t\t\tZ\n",
      "N\t\t\tN\n",
      "O\t\t\tO\n",
      "B\t\t\tB\n",
      "C\t\t\tC\n",
      "G\t\t\tG\n",
      "J\t\t\tJ\n",
      "E\t\t\tE\n",
      "N\t\t\tN\n",
      "J\t\t\tJ\n",
      "Q\t\t\tH\n",
      "B\t\t\tP\n",
      "G\t\t\tO\n",
      "O\t\t\tO\n",
      "B\t\t\tB\n",
      "E\t\t\tX\n",
      "R\t\t\tD\n",
      "S\t\t\tS\n",
      "O\t\t\tO\n",
      "O\t\t\tO\n",
      "G\t\t\tG\n",
      "B\t\t\tB\n",
      "R\t\t\tH\n",
      "C\t\t\tC\n",
      "A\t\t\tA\n",
      "W\t\t\tW\n",
      "P\t\t\tP\n",
      "I\t\t\tI\n",
      "N\t\t\tN\n",
      "M\t\t\tM\n",
      "K\t\t\tG\n",
      "M\t\t\tN\n",
      "A\t\t\tA\n",
      "Z\t\t\tH\n",
      "N\t\t\tK\n",
      "N\t\t\tN\n",
      "M\t\t\tM\n",
      "F\t\t\tF\n",
      "W\t\t\tW\n",
      "A\t\t\tA\n",
      "S\t\t\tS\n",
      "E\t\t\tE\n",
      "R\t\t\tT\n",
      "J\t\t\tJ\n",
      "H\t\t\tH\n",
      "N\t\t\tN\n",
      "R\t\t\tK\n",
      "W\t\t\tW\n",
      "W\t\t\tW\n",
      "U\t\t\tU\n",
      "S\t\t\tL\n",
      "Z\t\t\tZ\n",
      "Z\t\t\tZ\n",
      "Z\t\t\tZ\n",
      "G\t\t\tG\n",
      "T\t\t\tT\n",
      "J\t\t\tJ\n",
      "V\t\t\tV\n",
      "W\t\t\tW\n",
      "L\t\t\tL\n",
      "M\t\t\tM\n",
      "U\t\t\tU\n",
      "W\t\t\tW\n",
      "O\t\t\tG\n",
      "A\t\t\tA\n",
      "T\t\t\tT\n",
      "J\t\t\tJ\n",
      "C\t\t\tC\n",
      "G\t\t\tG\n",
      "D\t\t\tD\n",
      "T\t\t\tY\n",
      "Y\t\t\tY\n",
      "X\t\t\tX\n",
      "N\t\t\tN\n",
      "Y\t\t\tY\n",
      "S\t\t\tS\n",
      "K\t\t\tK\n",
      "U\t\t\tU\n",
      "U\t\t\tW\n",
      "R\t\t\tR\n",
      "R\t\t\tB\n",
      "T\t\t\tT\n",
      "R\t\t\tR\n",
      "H\t\t\tH\n",
      "R\t\t\tR\n",
      "M\t\t\tM\n",
      "O\t\t\tO\n",
      "W\t\t\tW\n",
      "X\t\t\tX\n",
      "R\t\t\tR\n",
      "X\t\t\tX\n",
      "N\t\t\tN\n",
      "H\t\t\tH\n",
      "C\t\t\tC\n",
      "E\t\t\tC\n",
      "J\t\t\tJ\n",
      "V\t\t\tV\n",
      "V\t\t\tV\n",
      "I\t\t\tI\n",
      "R\t\t\tR\n",
      "W\t\t\tW\n",
      "X\t\t\tH\n",
      "N\t\t\tN\n",
      "E\t\t\tE\n",
      "U\t\t\tU\n",
      "A\t\t\tM\n",
      "A\t\t\tA\n",
      "B\t\t\tB\n",
      "E\t\t\tE\n",
      "K\t\t\tK\n",
      "T\t\t\tT\n",
      "F\t\t\tF\n",
      "Y\t\t\tY\n",
      "D\t\t\tT\n",
      "H\t\t\tH\n",
      "W\t\t\tW\n",
      "W\t\t\tW\n",
      "O\t\t\tO\n",
      "Q\t\t\tG\n",
      "W\t\t\tW\n",
      "L\t\t\tL\n",
      "Q\t\t\tQ\n",
      "R\t\t\tR\n",
      "U\t\t\tK\n",
      "B\t\t\tD\n",
      "P\t\t\tP\n",
      "T\t\t\tT\n",
      "B\t\t\tB\n",
      "S\t\t\tL\n",
      "V\t\t\tV\n",
      "Q\t\t\tQ\n",
      "G\t\t\tG\n",
      "K\t\t\tS\n",
      "G\t\t\tW\n",
      "V\t\t\tV\n",
      "L\t\t\tL\n",
      "D\t\t\tD\n",
      "R\t\t\tR\n",
      "L\t\t\tL\n",
      "C\t\t\tC\n",
      "N\t\t\tN\n",
      "V\t\t\tV\n",
      "I\t\t\tI\n",
      "P\t\t\tP\n",
      "K\t\t\tC\n",
      "F\t\t\tF\n",
      "W\t\t\tW\n",
      "A\t\t\tA\n",
      "P\t\t\tP\n",
      "F\t\t\tT\n",
      "H\t\t\tH\n",
      "B\t\t\tB\n",
      "K\t\t\tK\n",
      "I\t\t\tI\n",
      "W\t\t\tW\n",
      "R\t\t\tR\n",
      "J\t\t\tJ\n",
      "K\t\t\tR\n",
      "K\t\t\tK\n",
      "A\t\t\tA\n",
      "Q\t\t\tQ\n",
      "Q\t\t\tQ\n",
      "A\t\t\tA\n",
      "M\t\t\tM\n",
      "V\t\t\tV\n",
      "U\t\t\tU\n",
      "G\t\t\tG\n",
      "O\t\t\tO\n",
      "U\t\t\tU\n",
      "H\t\t\tH\n",
      "V\t\t\tV\n",
      "G\t\t\tG\n",
      "Q\t\t\tQ\n",
      "I\t\t\tI\n",
      "T\t\t\tT\n",
      "G\t\t\tG\n",
      "F\t\t\tI\n"
     ]
    }
   ],
   "source": [
    "# Print the predicted labels and corresponding actual labels\n",
    "print(\"Predicted Labels\\tActual Labels\")\n",
    "for i in range(len(predicted_letters)):\n",
    "    print(f\"{predicted_letters[i]}\\t\\t\\t{actual_letters[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766fd158-9b1b-46e8-9767-8f1237e2bebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
